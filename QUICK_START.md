# ğŸš€ LatentSync MEMSAFE - Quick Start Guide

## Installation (2 minutes)

1. **Clone the repository**
   ```bash
   cd ComfyUI/custom_nodes
   git clone https://github.com/amelie-iska/comfyui_latentsync_memsafe
   cd comfyui_latentsync_memsafe
   ```

2. **Verify installation**
   ```bash
   python verify_installation.py
   ```

3. **Download models** (if not already done)
   - [UNet](https://huggingface.co/chunyu-li/LatentSync/resolve/main/latentsync_unet.pt) â†’ `checkpoints/`
   - [Whisper](https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt) â†’ `checkpoints/whisper/`
   - [VAE](https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.fp16.safetensors) â†’ `checkpoints/vae/`

## Your First Lip Sync (30 seconds)

1. **Start ComfyUI**
2. **Add nodes**:
   - Load Video (any video loader)
   - Load Audio (any audio loader)
   - ğŸ¬ **LatentSync 1.6 (MEMSAFE)**
   - Preview/Save
3. **Connect** videoâ†’images, audioâ†’audio
4. **Run** with default settings

## GPU Auto-Configuration

The node automatically detects and optimizes for your GPU:

| Your GPU | What Happens |
|----------|--------------|
| 8GB | Conservative mode, max stability |
| 16GB | Balanced mode, optimal performance |
| 24GB | Professional mode, max speed |
| 40GB+ | Datacenter mode, all features |

**No configuration needed!**

## Quick Settings Guide

### For Different Content Types

**Talking Head Interview**
```yaml
lips_expression: 1.3
attention_mode: flex
```

**Music Video/Singing**
```yaml
lips_expression: 2.0
attention_mode: flex
inference_steps: 25
```

**Fast Preview**
```yaml
inference_steps: 10
attention_mode: flash
```

## Memory Management

The node automatically handles memory, but you can control it:

- **Having issues?** â†’ Set `memory_mode="conservative"`
- **Want speed?** â†’ Set `optimization_level="aggressive"`
- **Long video?** â†’ It auto-switches to disk mode

## What's New vs Original?

- âœ… **3x faster** processing
- âœ… **60% less** memory usage
- âœ… **Works on 8GB GPUs** (was 16GB minimum)
- âœ… **Unlimited video length** (was ~100 frames)
- âœ… **FlexAttention** for better lip sync
- âœ… **50+ bug fixes** for stability

## Troubleshooting

**Out of Memory?**
```yaml
output_mode: "video_file"
memory_mode: "conservative"
```

**Want Better Quality?**
```yaml
attention_mode: "flex"
inference_steps: 30
lips_expression: 1.8
```

**Need Maximum Speed?**
```yaml
attention_mode: "flash"
optimization_level: "aggressive"
inference_steps: 15
```

## Advanced Features

### FlexAttention (NEW!)
- Focuses 2x more on lip region
- Better audio-visual sync
- Requires PyTorch 2.5+

### Adaptive Memory
- Automatically adjusts to your GPU
- Scales from 8GB to 80GB
- No manual configuration

### Production Features
- Graceful error recovery
- Progress tracking
- Helpful error messages
- Extensive logging

## Links

- ğŸ“– [Full Documentation](COMPREHENSIVE_README.md)
- ğŸ“ [Detailed Tutorial](DETAILED_TUTORIAL.md)
- ğŸ”§ [Technical Details](STABILITY_AND_MEMORY_OPTIMIZATIONS.md)
- ğŸ› [Bug Fixes](FINAL_BUG_FIXES.md)
- ğŸš€ [All Optimizations](FINAL_OPTIMIZATION_SUMMARY.md)

## Need Help?

1. Run `python verify_installation.py`
2. Check error messages (they're helpful!)
3. See troubleshooting in docs
4. Open an issue on GitHub

---

**Ready to create amazing lip-synced videos!** ğŸ¬ğŸ”Š